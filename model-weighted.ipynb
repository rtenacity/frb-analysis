{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5612806",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, adjusted_rand_score, confusion_matrix\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, roc_curve, auc\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score, recall_score\n",
    "from itertools import product\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import optuna\n",
    "import plotly.express as px\n",
    "from collections import Counter\n",
    "import umap.umap_ as umap\n",
    "import matplotlib\n",
    "from sklearn.manifold import Isomap\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc, f1_score\n",
    "import sklearn.metrics\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "from os.path import join\n",
    "matplotlib.rcParams.update(matplotlib.rcParamsDefault)\n",
    "matplotlib.rcParams.update({\n",
    "    'font.family': 'serif',\n",
    "    'text.usetex': True,\n",
    "})\n",
    "def fill_repeater_from_source(row, data):\n",
    "    if row['Source'] == 'FRB20220912A':\n",
    "        return 1\n",
    "    else:\n",
    "        return row['Repeater']\n",
    "frb_data = pd.read_csv('frb-data.csv')\n",
    "frb_data['Repeater'] = frb_data['Repeater'].map({'Yes': 1, 'No': 0})\n",
    "frb_data['Repeater'] = frb_data['Repeater'].fillna(0)\n",
    "frb_data['Repeater'] = frb_data['Repeater'].astype(int)\n",
    "frb_data['Repeater'] = frb_data.apply(fill_repeater_from_source, axis=1, data=frb_data)\n",
    "\n",
    "frb_data['Repeater'].isna().sum()\n",
    "labels = frb_data['Repeater']\n",
    "\n",
    "# Function to clean numerical strings and convert to float\n",
    "def clean_numeric_value(value):\n",
    "    if isinstance(value, str):\n",
    "        value = value.strip()\n",
    "        if not value:\n",
    "            return np.nan\n",
    "        try:\n",
    "            # Remove special characters and split if necessary\n",
    "            for char in ['/', '+', '<', '>', '~']:\n",
    "                value = value.replace(char, '')\n",
    "            if '-' in value:\n",
    "                value = value.split('-')[0]\n",
    "            return float(value)\n",
    "        except ValueError:\n",
    "            return np.nan\n",
    "    try:\n",
    "        return float(value)\n",
    "    except (ValueError, TypeError):\n",
    "        return np.nan\n",
    "    \n",
    "error_features = [\n",
    "    'DM_SNR', 'DM_alig', 'Flux_density', 'Fluence', 'Energy',\n",
    "    'Polar_l', 'Polar_c', 'RM_syn', 'RM_QUfit', 'Scatt_t', \n",
    "    #'Scin_f'\n",
    "]\n",
    "base_features = [\n",
    "    'Observing_band', \n",
    "    # 'GL', 'GB', 'SNR', \n",
    "    'Freq_high',\n",
    "    'Freq_low', 'Freq_peak', \n",
    "    'Width'\n",
    "    # 'Repeater',\n",
    "    #'MJD'\n",
    "]\n",
    "\n",
    "source_counts = frb_data.groupby('Source').size()            # # signals per source\n",
    "unique_sources = frb_data['Source'].nunique()                # N\n",
    "repeater_sources = frb_data.loc[frb_data['Repeater']==1,'Source'].nunique()   # n_r\n",
    "nonrep_sources = frb_data.loc[frb_data['Repeater']==0,'Source'].nunique()     # n_nr\n",
    "\n",
    "# 2) Broadcast n_s to each row\n",
    "frb_data['n_s'] = frb_data['Source'].map(source_counts)\n",
    "\n",
    "# 3) Compute the per-row weight\n",
    "def compute_weight(row):\n",
    "    if row['Repeater'] == 1:\n",
    "        return (1.0 / row['n_s']) * (repeater_sources / unique_sources)\n",
    "    else:\n",
    "        return nonrep_sources / unique_sources\n",
    "\n",
    "frb_data['weight'] = frb_data.apply(compute_weight, axis=1)\n",
    "# weights = np.ones(len(frb_data['weight']))\n",
    "weights = frb_data['weight']\n",
    "\n",
    "\n",
    "for feature in base_features + error_features:\n",
    "    frb_data[feature] = frb_data[feature].apply(clean_numeric_value)\n",
    "\n",
    "for feature in error_features:\n",
    "    frb_data[f'{feature}_err'] = frb_data[f'{feature}_err'].apply(clean_numeric_value)\n",
    "\n",
    "for feature in error_features:\n",
    "    frb_data[f'{feature}_upper'] = frb_data[feature] + frb_data[f'{feature}_err']\n",
    "    frb_data[f'{feature}_lower'] = frb_data[feature] - frb_data[f'{feature}_err']\n",
    "    frb_data[f'{feature}_lower'] = frb_data[f'{feature}_lower'].clip(lower=0)\n",
    "\n",
    "features = (\n",
    "    base_features +\n",
    "    error_features +\n",
    "    [f'{feature}_upper' for feature in error_features] +\n",
    "    [f'{feature}_lower' for feature in error_features]\n",
    ")\n",
    "frb_data_clean = frb_data[features].fillna(0)\n",
    "scaler = StandardScaler()\n",
    "frb_data_scaled = scaler.fit_transform(frb_data_clean)\n",
    "\n",
    "# Retain the original indices\n",
    "indices = frb_data_clean.index\n",
    "\n",
    "# Split the data and retain indices\n",
    "train_data, val_data, train_labels, val_labels, train_indices, val_indices = train_test_split(\n",
    "    frb_data_scaled, labels, indices, test_size=0.2, random_state=42, stratify=labels\n",
    ")\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "train_tensor = torch.tensor(train_data, dtype=torch.float32)\n",
    "val_tensor = torch.tensor(val_data, dtype=torch.float32)\n",
    "train_labels_tensor = torch.tensor(train_labels.values, dtype=torch.long)\n",
    "val_labels_tensor = torch.tensor(val_labels.values, dtype=torch.long)\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "batch_size = 64\n",
    "train_dataset = TensorDataset(train_tensor, train_labels_tensor)\n",
    "val_dataset = TensorDataset(val_tensor, val_labels_tensor)\n",
    "\n",
    "\n",
    "class SupervisedVAE(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, latent_dim, dropout_rate=0.3, activation=nn.LeakyReLU(0.1)):\n",
    "        super(SupervisedVAE, self).__init__()\n",
    "\n",
    "        self.activation = activation\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            self.activation,\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            self.activation,\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim, hidden_dim),  # Additional dense layer\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            self.activation,\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "\n",
    "        self.fc_mu = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(hidden_dim, latent_dim)\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            self.activation,\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            self.activation,\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim, hidden_dim),  # Additional dense layer\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            self.activation,\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim, input_dim)\n",
    "        )\n",
    "\n",
    "        # Classification head for binary classification - tune hyperparameters\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dim // 2),\n",
    "            self.activation,\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim // 2, hidden_dim // 4),  # Added extra linear layer\n",
    "            self.activation,\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim // 4, 1),\n",
    "        )\n",
    "\n",
    "\n",
    "    def encode(self, x):\n",
    "        h = self.encoder(x)\n",
    "        return self.fc_mu(h), self.fc_logvar(h)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def decode(self, z):\n",
    "        return self.decoder(z)\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        recon_x = self.decode(z)\n",
    "        class_prob = self.classifier(mu)\n",
    "        return recon_x, mu, logvar, class_prob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8cfee4f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "443\n",
      "Number of NaN values in 'Repeater' column before processing: 443\n",
      "Number of NaN values in 'Repeater' column after processing: 0\n"
     ]
    }
   ],
   "source": [
    "def loss_function(recon_x, x, mu, logvar, class_prob, labels, beta, gamma, class_weight, classification_multiplier):\n",
    "    reconstruction_loss_fn = nn.MSELoss(reduction='sum')\n",
    "    pos_weight = torch.tensor([class_weight], dtype=torch.float32, device=device)\n",
    "    classification_loss_fn = nn.BCEWithLogitsLoss(pos_weight=pos_weight) # check this loss function\n",
    "    recon_loss = reconstruction_loss_fn(recon_x, x)\n",
    "    kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    class_loss = classification_multiplier * classification_loss_fn(class_prob, labels.unsqueeze(1).float())\n",
    "    total_loss = recon_loss + beta * kl_loss + gamma * class_loss\n",
    "    return total_loss, recon_loss, kl_loss, class_loss\n",
    "\n",
    "def weighted_loss_function(recon_x, x, mu, logvar, class_prob, \n",
    "                           labels, sample_weights, class_weight,\n",
    "                           beta, gamma, classification_multiplier):\n",
    "    \n",
    "    recon_per_elem = F.mse_loss(recon_x, x, reduction='none')\n",
    "    recon_per_sample = recon_per_elem.view(recon_per_elem.size(0), -1).sum(dim=1)\n",
    "\n",
    "    # KL: closed-form per-sample\n",
    "    kl_per_sample = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp(), dim=1)\n",
    "\n",
    "    # classification: per-sample\n",
    "    class_per_sample = F.binary_cross_entropy_with_logits(\n",
    "        class_prob.squeeze(), \n",
    "        labels.float(), \n",
    "        reduction='none',\n",
    "        pos_weight=torch.tensor([class_weight], dtype=torch.float32, device=device)\n",
    "    )\n",
    "\n",
    "    # combine terms\n",
    "    loss_per_sample = (\n",
    "        recon_per_sample\n",
    "        + beta * kl_per_sample\n",
    "        + gamma * classification_multiplier * class_per_sample\n",
    "    )\n",
    "\n",
    "    # now weight each sample\n",
    "    # Option A: simple mean of weighted losses\n",
    "    total_loss = torch.mean(sample_weights * loss_per_sample)\n",
    "    recon_loss = torch.mean(sample_weights * recon_per_sample)\n",
    "    kl_loss = torch.mean(sample_weights * kl_per_sample)\n",
    "    class_loss = torch.mean(sample_weights * class_per_sample)\n",
    "    \n",
    "    return total_loss, recon_loss, kl_loss, class_loss\n",
    "\n",
    "\n",
    "input_dim = val_tensor.shape[1]\n",
    "stop_patience = 8\n",
    "\n",
    "\n",
    "def evaluate_classifier(model, dataloader, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for data, labels in dataloader:\n",
    "            data = data.to(device)\n",
    "            labels = labels.to(device)\n",
    "            class_logits = model(data)[-1]\n",
    "            preds = (class_logits > 0.5).float().cpu().numpy().squeeze()\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    all_preds = np.array(all_preds)\n",
    "    all_labels = np.array(all_labels)\n",
    "    \n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    class_report = classification_report(all_labels, all_preds, target_names=[\"Non-Repeater\", \"Repeater\"])\n",
    "    conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "    recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "    \n",
    "    false_positives = np.sum((all_labels == 0) & (all_preds == 1))\n",
    "\n",
    "    return accuracy, class_report, conf_matrix, recall, false_positives  # Return F1 score as well\n",
    "\n",
    "def get_activation_function(name):\n",
    "    if name == 'ReLU':\n",
    "        return nn.ReLU()\n",
    "    elif name == 'LeakyReLU':\n",
    "        return nn.LeakyReLU(0.1)\n",
    "    elif name == 'ELU':\n",
    "        return nn.ELU()\n",
    "    elif name == 'SELU':\n",
    "        return nn.SELU()\n",
    "    elif name == 'GELU':\n",
    "        return nn.GELU()\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown activation function: {name}\")\n",
    "    \n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc, f1_score\n",
    "import sklearn.metrics\n",
    "\n",
    "def evaluate_classifier_full(model, dataloader, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for data, labels, _ in dataloader:\n",
    "            data = data.to(device)\n",
    "            class_logits = model(data)[-1]\n",
    "            preds = (class_logits > 0.5).float().cpu().numpy().squeeze()\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    all_preds = np.array(all_preds)\n",
    "    all_labels = np.array(all_labels)\n",
    "    \n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    f1 = sklearn.metrics.f1_score(all_labels, all_preds)\n",
    "    class_report = classification_report(all_labels, all_preds, target_names=[\"Non-Repeater\", \"Repeater\"])\n",
    "    conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "    \n",
    "    return accuracy, class_report, conf_matrix, all_preds, all_labels\n",
    "\n",
    "original_data = pd.read_csv('frb-data.csv')\n",
    "original_data['Repeater'] = original_data['Repeater'].map({'Yes': 1, 'No': 0})\n",
    "print(original_data['Repeater'].isna().sum())\n",
    "\n",
    "print(f\"Number of NaN values in 'Repeater' column before processing: {original_data['Repeater'].isna().sum()}\")\n",
    "# Apply the function row-wise\n",
    "original_data['Repeater'] = original_data.apply(fill_repeater_from_source, axis=1, data=original_data)\n",
    "\n",
    "print(f\"Number of NaN values in 'Repeater' column after processing: {original_data['Repeater'].isna().sum()}\")\n",
    "best_params = {'hidden_dim': 1082, 'latent_dim': 18, 'beta': 1.149574612306723, 'gamma': 1.9210647260496314, 'dropout_rate': 0.13093239424733344, 'lr': 0.0011823749066137313, 'scheduler_patience': 7, 'class_weight': 0.35488674730648145, 'activation': 'ReLU', 'classification_multiplier': 7817.124805902009}\n",
    "\n",
    "beta = best_params[\"beta\"]\n",
    "gamma = best_params[\"gamma\"]\n",
    "lr = best_params[\"lr\"]\n",
    "scheduler_patience = best_params[\"scheduler_patience\"]\n",
    "num_epochs = 150\n",
    "def train_supervised(model, optimizer, scheduler, epoch, beta, gamma, class_weight, classification_multiplier, train_loader):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    recon_loss_total = 0\n",
    "    kl_loss_total = 0\n",
    "    classification_loss_total = 0\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for batch_idx, (data, labels, sample_weights) in enumerate(train_loader):\n",
    "        data, labels, sample_weights = data.to(device), labels.to(device), sample_weights.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar, class_logits = model(data)\n",
    "        \n",
    "        # Supervised loss function\n",
    "        loss, recon_loss, kl_loss, classification_loss = weighted_loss_function(\n",
    "            recon_batch, data, mu, logvar, class_logits, labels, sample_weights, class_weight,\n",
    "            beta, gamma, classification_multiplier\n",
    "        )\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        recon_loss_total += recon_loss.item()\n",
    "        kl_loss_total += kl_loss.item()\n",
    "        classification_loss_total += classification_loss.item()\n",
    "        \n",
    "        predicted = (class_logits > 0.5).float()\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted.squeeze() == labels).sum().item()\n",
    "        \n",
    "        # if batch_idx % 100 == 0:\n",
    "            # print(classification_loss)\n",
    "            # print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} '\n",
    "            #       f'({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item() / len(data):.6f}')\n",
    "    \n",
    "    # Calculate average loss and accuracy for the epoch\n",
    "    avg_loss = train_loss / len(train_loader.dataset)\n",
    "    avg_recon = recon_loss_total / len(train_loader.dataset)\n",
    "    avg_kl = kl_loss_total / len(train_loader.dataset)\n",
    "    avg_class = classification_loss_total / len(train_loader.dataset)\n",
    "    accuracy = correct / total\n",
    "    \n",
    "    # print(f'====> Epoch: {epoch} Average loss: {avg_loss:.4f}, Recon: {avg_recon:.4f}, KL: {avg_kl:.4f}, '\n",
    "    #       f'Class: {avg_class:.4f}, Accuracy: {accuracy:.4f}')\n",
    "    return avg_loss, avg_recon, avg_kl, avg_class, accuracy\n",
    "\n",
    "def validate_supervised(model, scheduler, optimizer, epoch, beta, gamma, class_weight, classification_multiplier, val_loader):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    recon_loss_total = 0\n",
    "    kl_loss_total = 0\n",
    "    classification_loss_total = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, labels, sample_weights in val_loader:\n",
    "            data, labels, sample_weights = data.to(device), labels.to(device) , sample_weights.to(device)\n",
    "            recon_batch, mu, logvar, class_logits = model(data)\n",
    "            \n",
    "            loss, recon_loss, kl_loss, classification_loss = weighted_loss_function(\n",
    "                recon_batch, data, mu, logvar, class_logits, labels, sample_weights, class_weight,\n",
    "                beta, gamma, classification_multiplier\n",
    "            )\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            recon_loss_total += recon_loss.item()\n",
    "            kl_loss_total += kl_loss.item()\n",
    "            classification_loss_total += classification_loss.item()\n",
    "            \n",
    "            predicted = (class_logits > 0.5).float()\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted.squeeze() == labels).sum().item()\n",
    "    \n",
    "    avg_loss = val_loss / len(val_loader.dataset)\n",
    "    avg_recon = recon_loss_total / len(val_loader.dataset)\n",
    "    avg_kl = kl_loss_total / len(val_loader.dataset)\n",
    "    avg_class = classification_loss_total / len(val_loader.dataset)\n",
    "    accuracy = correct / total\n",
    "    \n",
    "    # print(f'====> Validation loss: {avg_loss:.4f}, Recon: {avg_recon:.4f}, KL: {avg_kl:.4f}, '\n",
    "    #       f'Class: {avg_class:.4f}, Accuracy: {accuracy:.4f}')\n",
    "    return avg_loss, avg_recon, avg_kl, avg_class, accuracy\n",
    "\n",
    "\n",
    "def early_stopping(val_losses, patience):\n",
    "    if len(val_losses) > patience:\n",
    "        if all(val_losses[-i-1] <= val_losses[-i] for i in range(1, patience+1)):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "garcia_list = '''\n",
    "FRB20180907E\n",
    "FRB20180920B\n",
    "FRB20180928A\n",
    "FRB20181017B\n",
    "FRB20181022E\n",
    "FRB20181125A\n",
    "FRB20181125A\n",
    "FRB20181125A\n",
    "FRB20181214A\n",
    "FRB20181220A\n",
    "FRB20181226E\n",
    "FRB20181229B\n",
    "FRB20190112A\n",
    "FRB20190128C\n",
    "FRB20190206B\n",
    "FRB20190206A\n",
    "FRB20190218B\n",
    "FRB20190223A\n",
    "FRB20190308C\n",
    "FRB20190308C\n",
    "FRB20190323D\n",
    "FRB20190329A\n",
    "FRB20190410A\n",
    "FRB20190412B\n",
    "FRB20190423B\n",
    "FRB20190423B\n",
    "FRB20190429B\n",
    "FRB20190430A\n",
    "FRB20190527A\n",
    "FRB20190527A\n",
    "FRB20190601C\n",
    "FRB20190601C\n",
    "FRB20190617B\n",
    "FRB20180910A\n",
    "FRB20190210C\n",
    "FRB20200726D\n",
    "'''.split()\n",
    "\n",
    "luo_list = '''\n",
    "FRB20181229B\n",
    "FRB20190423B\n",
    "FRB20190410A\n",
    "FRB20181017B\n",
    "FRB20181128C\n",
    "FRB20190422A\n",
    "FRB20190409B\n",
    "FRB20190329A\n",
    "FRB20190423B\n",
    "FRB20190206A\n",
    "FRB20190128C\n",
    "FRB20190106A\n",
    "FRB20190129A\n",
    "FRB20181030E\n",
    "FRB20190527A\n",
    "FRB20190218B\n",
    "FRB20190609A\n",
    "FRB20190412B\n",
    "FRB20190125B\n",
    "FRB20181231B\n",
    "FRB20181221A\n",
    "FRB20190112A\n",
    "FRB20190125A\n",
    "FRB20181218C\n",
    "FRB20190429B\n",
    "FRB20190109B\n",
    "FRB20190206B\n",
    "'''.split()\n",
    "\n",
    "zhu_ge_list = '''\n",
    "FRB20180911A\n",
    "FRB20180915B\n",
    "FRB20180920B\n",
    "FRB20180923A\n",
    "FRB20180923C\n",
    "FRB20180928A\n",
    "FRB20181013E\n",
    "FRB20181017B\n",
    "FRB20181030E\n",
    "FRB20181125A\n",
    "FRB20181125A\n",
    "FRB20181125A\n",
    "FRB20181130A\n",
    "FRB20181214A\n",
    "FRB20181220A\n",
    "FRB20181221A\n",
    "FRB20181226E\n",
    "FRB20181229B\n",
    "FRB20181231B\n",
    "FRB20190106B\n",
    "FRB20190109B\n",
    "FRB20190110C\n",
    "FRB20190111A\n",
    "FRB20190112A\n",
    "FRB20190129A\n",
    "FRB20190204A\n",
    "FRB20190206A\n",
    "FRB20190218B\n",
    "FRB20190220A\n",
    "FRB20190221A\n",
    "FRB20190222B\n",
    "FRB20190223A\n",
    "FRB20190228A\n",
    "FRB20190308C\n",
    "FRB20190308C\n",
    "FRB20190308B\n",
    "FRB20190308B\n",
    "FRB20190323D\n",
    "FRB20190329A\n",
    "FRB20190403E\n",
    "FRB20190409B\n",
    "FRB20190410A\n",
    "FRB20190412B\n",
    "FRB20190418A\n",
    "FRB20190419A\n",
    "FRB20190422A\n",
    "FRB20190422A\n",
    "FRB20190423A\n",
    "FRB20190423B\n",
    "FRB20190423B\n",
    "FRB20190429B\n",
    "FRB20190430A\n",
    "FRB20190517C\n",
    "FRB20190527A\n",
    "FRB20190527A\n",
    "FRB20190531C\n",
    "FRB20190601B\n",
    "FRB20190601C\n",
    "FRB20190601C\n",
    "FRB20190609A\n",
    "FRB20190617A\n",
    "FRB20190617B\n",
    "FRB20190618A\n",
    "FRB20190625A\n",
    "'''.split()\n",
    "\n",
    "# all_false_positives = []\n",
    "# all_false_negatives = []\n",
    "# all_true_positives = []\n",
    "# all_true_negatives = []\n",
    "\n",
    "# num_epochs = 100\n",
    "\n",
    "# n_folds = 5\n",
    "# skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# full_data_tensor = torch.tensor(frb_data_scaled, dtype=torch.float32)\n",
    "# full_labels_tensor = torch.tensor(labels.values, dtype=torch.long)\n",
    "\n",
    "# for fold, (train_index, val_index) in enumerate(skf.split(frb_data_scaled, labels)):\n",
    "#     print(f\"\\n=== Fold {fold + 1}/{n_folds} ===\")\n",
    "    \n",
    "#     train_data, val_data = frb_data_scaled[train_index], frb_data_scaled[val_index]\n",
    "#     train_labels, val_labels = labels.iloc[train_index], labels.iloc[val_index]\n",
    "    \n",
    "    \n",
    "#     train_tensor = torch.tensor(train_data, dtype=torch.float32)\n",
    "#     val_tensor = torch.tensor(val_data, dtype=torch.float32)\n",
    "#     train_labels_tensor = torch.tensor(train_labels.values, dtype=torch.long)\n",
    "#     val_labels_tensor = torch.tensor(val_labels.values, dtype=torch.long)\n",
    "    \n",
    "#     train_weights = torch.tensor(weights.iloc[train_index].values, dtype=torch.float32)\n",
    "#     val_weights   = torch.tensor(weights.iloc[val_index].values,   dtype=torch.float32)\n",
    "    \n",
    "#     # train_weights = torch.tensor(weights[train_index], dtype=torch.float32)\n",
    "#     # val_weights   = torch.tensor(weights[val_index],   dtype=torch.float32)\n",
    "\n",
    "\n",
    "    \n",
    "#     train_dataset = TensorDataset(train_tensor, train_labels_tensor, train_weights)\n",
    "#     val_dataset   = TensorDataset(val_tensor,   val_labels_tensor,   val_weights)\n",
    "\n",
    "#     train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "#     val_loader   = DataLoader(val_dataset,   batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    \n",
    "#     best_model = SupervisedVAE(\n",
    "#         input_dim,\n",
    "#         best_params[\"hidden_dim\"],\n",
    "#         best_params[\"latent_dim\"],\n",
    "#         best_params[\"dropout_rate\"],\n",
    "#         get_activation_function(best_params[\"activation\"])\n",
    "#     ).to(device)\n",
    "    \n",
    "#     optimizer = torch.optim.Adam(best_model.parameters(), lr=lr)\n",
    "#     scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=scheduler_patience)\n",
    "    \n",
    "#     # Train the model\n",
    "#     for epoch in range(1, num_epochs + 1):\n",
    "#         train_loss, _, _, _, train_accuracy = train_supervised(best_model, optimizer, scheduler, epoch, beta, gamma, best_params['class_weight'], best_params['classification_multiplier'])\n",
    "#         val_loss, _, _, _, val_accuracy = validate_supervised(best_model, optimizer, scheduler, epoch, beta, gamma, best_params['class_weight'], best_params['classification_multiplier'])\n",
    "#         # train_loss, _, _, _, train_accuracy = train_supervised(best_model, optimizer, scheduler, epoch, beta, gamma, 1, best_params['classification_multiplier'])\n",
    "#         # val_loss, _, _, _, val_accuracy = validate_supervised(best_model, optimizer, scheduler, epoch, beta, gamma, 1, best_params['classification_multiplier'])\n",
    "#         scheduler.step(val_loss)\n",
    "        \n",
    "#         # Early stopping\n",
    "#         if early_stopping([val_loss], stop_patience):\n",
    "#             print(f\"Early stopping triggered at epoch {epoch}\")\n",
    "#             break\n",
    "\n",
    "#     val_accuracy, val_class_report, val_conf_matrix, val_preds, val_labels = evaluate_classifier_full(best_model, val_loader, device)\n",
    "    \n",
    "#     # print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
    "#     # print(\"Classification Report:\\n\", val_class_report)\n",
    "#     # print(\"Confusion Matrix:\\n\", val_conf_matrix)\n",
    "    \n",
    "#     misclassified_non_repeaters = (val_labels == 0) & (val_preds == 1)\n",
    "#     misclassified_indices = val_index[misclassified_non_repeaters]\n",
    "#     misclassified_sources = original_data.loc[misclassified_indices, \"Source\"].drop_duplicates()\n",
    "    \n",
    "#     false_positives_fold = original_data.loc[val_index[(val_labels == 0) & (val_preds == 1)], \"Source\"]\n",
    "#     false_negatives_fold = original_data.loc[val_index[(val_labels == 1) & (val_preds == 0)], \"Source\"]\n",
    "#     true_positives_fold = original_data.loc[val_index[(val_labels == 1) & (val_preds == 1)], \"Source\"]\n",
    "#     true_negatives_fold = original_data.loc[val_index[(val_labels == 0) & (val_preds == 0)], \"Source\"]\n",
    "    \n",
    "#     # # fold_false_positives = []\n",
    "#     # for source in misclassified_sources:\n",
    "#     #     # fold_false_positives.append(source)\n",
    "#     #     if source in garcia_list or source in luo_list or source in zhu_ge_list:\n",
    "#     #         print(f\"False positive in fold {fold + 1}: {source}\")\n",
    "            \n",
    "#     all_false_negatives.extend(false_negatives_fold)\n",
    "#     all_true_positives.extend(true_positives_fold)\n",
    "#     all_true_negatives.extend(true_negatives_fold)\n",
    "#     all_false_positives.extend(false_positives_fold)\n",
    "    \n",
    "    \n",
    "# all_false_positives = pd.Series(all_false_positives)\n",
    "# all_false_negatives = pd.Series(all_false_negatives)\n",
    "# all_true_positives = pd.Series(all_true_positives)\n",
    "# all_true_negatives = pd.Series(all_true_negatives)\n",
    "# print(\"\")\n",
    "\n",
    "# print(\"\\n=== Summary ===\")\n",
    "# print(f\"Total False Positives: {all_false_positives.size}\")\n",
    "# print(f\"Total False Negatives: {all_false_negatives.size}\")\n",
    "# print(f\"Total True Positives: {all_true_positives.size}\")\n",
    "# print(f\"Total True Negatives: {all_true_negatives.size}\")\n",
    "\n",
    "# conf_mat_dups = np.zeros((2, 2))\n",
    "# conf_mat_dups[0, 0] = all_true_negatives.size\n",
    "# conf_mat_dups[0, 1] = all_false_positives.size\n",
    "# conf_mat_dups[1, 0] = all_false_negatives.size\n",
    "# conf_mat_dups[1, 1] = all_true_positives.size\n",
    "\n",
    "\n",
    "# conf_mat_dups = pd.DataFrame(conf_mat_dups, index=[\"Non-Repeater\", \"Repeater\"], columns=[\"Non-Repeater\", \"Repeater\"])\n",
    "# print(\"\\nConfusion Matrix (with duplicates):\")\n",
    "# print(conf_mat_dups)\n",
    "\n",
    "# print(\"accuracy_score\")\n",
    "# accuracy = (all_true_positives.size + all_true_negatives.size) / (all_false_positives.size + all_false_negatives.size + all_true_positives.size + all_true_negatives.size)\n",
    "# print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ed4971",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-12 02:28:48,116] A new study created in memory with name: no-name-068e3e70-264a-42ec-bba8-521e507368bd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 1/5 ===\n",
      "Validation Accuracy: 0.9435\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "Non-Repeater       0.74      0.52      0.61       149\n",
      "    Repeater       0.96      0.98      0.97      1584\n",
      "\n",
      "    accuracy                           0.94      1733\n",
      "   macro avg       0.85      0.75      0.79      1733\n",
      "weighted avg       0.94      0.94      0.94      1733\n",
      "\n",
      "Confusion Matrix:\n",
      " [[  78   71]\n",
      " [  27 1557]]\n",
      "\n",
      "=== Fold 2/5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-06-12 02:31:05,030] Trial 0 failed with parameters: {'hidden_dim': 1927, 'latent_dim': 14, 'beta': 0.34696346411118173, 'gamma': 1.616328012477356, 'dropout_rate': 0.23603027859606482, 'lr': 0.007167503069322618, 'scheduler_patience': 6, 'class_weight': 1.4240300207238379, 'activation': 'LeakyReLU', 'classification_multiplier': 11821.27764892459} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/frb-analysis/.frb-analysis/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_564550/1241230763.py\", line 74, in objective\n",
      "    train_loss, _, _, _, train_accuracy = train_supervised(best_model, optimizer, scheduler, epoch, beta, gamma, class_weight, classification_multiplier, train_loader)\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_564550/2546627414.py\", line 155, in train_supervised\n",
      "    train_loss += loss.item()\n",
      "                  ^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "[W 2025-06-12 02:31:05,031] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 142\u001b[39m\n\u001b[32m    139\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m accuracy\n\u001b[32m    141\u001b[39m study = optuna.create_study(direction=\u001b[33m'\u001b[39m\u001b[33mmaximize\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m142\u001b[39m \u001b[43mstudy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m350\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/frb-analysis/.frb-analysis/lib/python3.12/site-packages/optuna/study/study.py:475\u001b[39m, in \u001b[36mStudy.optimize\u001b[39m\u001b[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m    373\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimize\u001b[39m(\n\u001b[32m    374\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    375\u001b[39m     func: ObjectiveFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    382\u001b[39m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    383\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    384\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[32m    385\u001b[39m \n\u001b[32m    386\u001b[39m \u001b[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    473\u001b[39m \u001b[33;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[32m    474\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m475\u001b[39m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    476\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    477\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    478\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    479\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    482\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    483\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    484\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    485\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/frb-analysis/.frb-analysis/lib/python3.12/site-packages/optuna/study/_optimize.py:63\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     62\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     64\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     76\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs == -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/frb-analysis/.frb-analysis/lib/python3.12/site-packages/optuna/study/_optimize.py:160\u001b[39m, in \u001b[36m_optimize_sequential\u001b[39m\u001b[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[39m\n\u001b[32m    157\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m160\u001b[39m     frozen_trial = \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    162\u001b[39m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[32m    163\u001b[39m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[32m    164\u001b[39m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[32m    165\u001b[39m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[32m    166\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/frb-analysis/.frb-analysis/lib/python3.12/site-packages/optuna/study/_optimize.py:248\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    241\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mShould not reach.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    243\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    244\u001b[39m     frozen_trial.state == TrialState.FAIL\n\u001b[32m    245\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    246\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[32m    247\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m248\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/frb-analysis/.frb-analysis/lib/python3.12/site-packages/optuna/study/_optimize.py:197\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    195\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001b[32m    196\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m197\u001b[39m         value_or_values = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    198\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.TrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    199\u001b[39m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[32m    200\u001b[39m         state = TrialState.PRUNED\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 74\u001b[39m, in \u001b[36mobjective\u001b[39m\u001b[34m(trial)\u001b[39m\n\u001b[32m     72\u001b[39m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[32m     73\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, num_epochs + \u001b[32m1\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m     train_loss, _, _, _, train_accuracy = \u001b[43mtrain_supervised\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbest_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgamma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclassification_multiplier\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     75\u001b[39m     val_loss, _, _, _, val_accuracy = validate_supervised(best_model, optimizer, scheduler, epoch, beta, gamma, class_weight, classification_multiplier, val_loader)\n\u001b[32m     76\u001b[39m     \u001b[38;5;66;03m# train_loss, _, _, _, train_accuracy = train_supervised(best_model, optimizer, scheduler, epoch, beta, gamma, 1, best_params['classification_multiplier'])\u001b[39;00m\n\u001b[32m     77\u001b[39m     \u001b[38;5;66;03m# val_loss, _, _, _, val_accuracy = validate_supervised(best_model, optimizer, scheduler, epoch, beta, gamma, 1, best_params['classification_multiplier'])\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 155\u001b[39m, in \u001b[36mtrain_supervised\u001b[39m\u001b[34m(model, optimizer, scheduler, epoch, beta, gamma, class_weight, classification_multiplier, train_loader)\u001b[39m\n\u001b[32m    152\u001b[39m loss.backward()\n\u001b[32m    153\u001b[39m optimizer.step()\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m train_loss += \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    156\u001b[39m recon_loss_total += recon_loss.item()\n\u001b[32m    157\u001b[39m kl_loss_total += kl_loss.item()\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "accuracy_max = 0\n",
    "\n",
    "def objective(trial):\n",
    "    global i, accuracy_max\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 128, 2048)\n",
    "    latent_dim = trial.suggest_int('latent_dim', 5, 40)\n",
    "    beta = trial.suggest_float('beta', 0.1, 2.0)\n",
    "    gamma = trial.suggest_float('gamma', 0.1, 2.0)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2)\n",
    "    scheduler_patience = trial.suggest_int('scheduler_patience', 2, 7)\n",
    "    class_weight = trial.suggest_float('class_weight', 0.05, 3)\n",
    "\n",
    "    activation_name = trial.suggest_categorical('activation', ['ReLU', 'LeakyReLU', 'ELU', 'SELU', 'GELU'])\n",
    "    activation = get_activation_function(activation_name)\n",
    "    classification_multiplier = trial.suggest_float('classification_multiplier', 5000, 15000)\n",
    "\n",
    "    pos_weight = torch.tensor([class_weight], dtype=torch.float32, device=device)\n",
    "\n",
    "    all_false_positives = []\n",
    "    all_false_negatives = []\n",
    "    all_true_positives = []\n",
    "    all_true_negatives = []\n",
    "\n",
    "    num_epochs = 100\n",
    "\n",
    "    n_folds = 5\n",
    "    skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "    full_data_tensor = torch.tensor(frb_data_scaled, dtype=torch.float32)\n",
    "    full_labels_tensor = torch.tensor(labels.values, dtype=torch.long)\n",
    "\n",
    "    for fold, (train_index, val_index) in enumerate(skf.split(frb_data_scaled, labels)):\n",
    "        print(f\"\\n=== Fold {fold + 1}/{n_folds} ===\")\n",
    "        \n",
    "        train_data, val_data = frb_data_scaled[train_index], frb_data_scaled[val_index]\n",
    "        train_labels, val_labels = labels.iloc[train_index], labels.iloc[val_index]\n",
    "        \n",
    "        \n",
    "        train_tensor = torch.tensor(train_data, dtype=torch.float32)\n",
    "        val_tensor = torch.tensor(val_data, dtype=torch.float32)\n",
    "        train_labels_tensor = torch.tensor(train_labels.values, dtype=torch.long)\n",
    "        val_labels_tensor = torch.tensor(val_labels.values, dtype=torch.long)\n",
    "        \n",
    "        train_weights = torch.tensor(weights.iloc[train_index].values, dtype=torch.float32)\n",
    "        val_weights   = torch.tensor(weights.iloc[val_index].values,   dtype=torch.float32)\n",
    "        \n",
    "        # train_weights = torch.tensor(weights[train_index], dtype=torch.float32)\n",
    "        # val_weights   = torch.tensor(weights[val_index],   dtype=torch.float32)\n",
    "\n",
    "\n",
    "        \n",
    "        train_dataset = TensorDataset(train_tensor, train_labels_tensor, train_weights)\n",
    "        val_dataset   = TensorDataset(val_tensor,   val_labels_tensor,   val_weights)\n",
    "\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        val_loader   = DataLoader(val_dataset,   batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        \n",
    "        best_model = SupervisedVAE(\n",
    "            input_dim,\n",
    "            hidden_dim,\n",
    "            latent_dim,\n",
    "            dropout_rate,\n",
    "            activation\n",
    "        ).to(device)\n",
    "        \n",
    "        optimizer = torch.optim.Adam(best_model.parameters(), lr=lr)\n",
    "        scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=scheduler_patience)\n",
    "        \n",
    "        # Train the model\n",
    "        for epoch in range(1, num_epochs + 1):\n",
    "            train_loss, _, _, _, train_accuracy = train_supervised(best_model, optimizer, scheduler, epoch, beta, gamma, class_weight, classification_multiplier, train_loader)\n",
    "            val_loss, _, _, _, val_accuracy = validate_supervised(best_model, optimizer, scheduler, epoch, beta, gamma, class_weight, classification_multiplier, val_loader)\n",
    "            # train_loss, _, _, _, train_accuracy = train_supervised(best_model, optimizer, scheduler, epoch, beta, gamma, 1, best_params['classification_multiplier'])\n",
    "            # val_loss, _, _, _, val_accuracy = validate_supervised(best_model, optimizer, scheduler, epoch, beta, gamma, 1, best_params['classification_multiplier'])\n",
    "            scheduler.step(val_loss)\n",
    "            \n",
    "            # Early stopping\n",
    "            if early_stopping([val_loss], stop_patience):\n",
    "                print(f\"Early stopping triggered at epoch {epoch}\")\n",
    "                break\n",
    "\n",
    "        val_accuracy, val_class_report, val_conf_matrix, val_preds, val_labels = evaluate_classifier_full(best_model, val_loader, device)\n",
    "        \n",
    "        print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
    "        print(\"Classification Report:\\n\", val_class_report)\n",
    "        print(\"Confusion Matrix:\\n\", val_conf_matrix)\n",
    "        \n",
    "        misclassified_non_repeaters = (val_labels == 0) & (val_preds == 1)\n",
    "        misclassified_indices = val_index[misclassified_non_repeaters]\n",
    "        misclassified_sources = original_data.loc[misclassified_indices, \"Source\"].drop_duplicates()\n",
    "        \n",
    "        false_positives_fold = original_data.loc[val_index[(val_labels == 0) & (val_preds == 1)], \"Source\"]\n",
    "        false_negatives_fold = original_data.loc[val_index[(val_labels == 1) & (val_preds == 0)], \"Source\"]\n",
    "        true_positives_fold = original_data.loc[val_index[(val_labels == 1) & (val_preds == 1)], \"Source\"]\n",
    "        true_negatives_fold = original_data.loc[val_index[(val_labels == 0) & (val_preds == 0)], \"Source\"]\n",
    "        \n",
    "        # # fold_false_positives = []\n",
    "        # for source in misclassified_sources:\n",
    "        #     # fold_false_positives.append(source)\n",
    "        #     if source in garcia_list or source in luo_list or source in zhu_ge_list:\n",
    "        #         print(f\"False positive in fold {fold + 1}: {source}\")\n",
    "                \n",
    "        all_false_negatives.extend(false_negatives_fold)\n",
    "        all_true_positives.extend(true_positives_fold)\n",
    "        all_true_negatives.extend(true_negatives_fold)\n",
    "        all_false_positives.extend(false_positives_fold)\n",
    "        \n",
    "        \n",
    "    all_false_positives = pd.Series(all_false_positives)\n",
    "    all_false_negatives = pd.Series(all_false_negatives)\n",
    "    all_true_positives = pd.Series(all_true_positives)\n",
    "    all_true_negatives = pd.Series(all_true_negatives)\n",
    "    print(\"\")\n",
    "\n",
    "    print(\"\\n=== Summary ===\")\n",
    "    print(f\"Total False Positives: {all_false_positives.size}\")\n",
    "    print(f\"Total False Negatives: {all_false_negatives.size}\")\n",
    "    print(f\"Total True Positives: {all_true_positives.size}\")\n",
    "    print(f\"Total True Negatives: {all_true_negatives.size}\")\n",
    "\n",
    "    conf_mat_dups = np.zeros((2, 2))\n",
    "    conf_mat_dups[0, 0] = all_true_negatives.size\n",
    "    conf_mat_dups[0, 1] = all_false_positives.size\n",
    "    conf_mat_dups[1, 0] = all_false_negatives.size\n",
    "    conf_mat_dups[1, 1] = all_true_positives.size\n",
    "\n",
    "\n",
    "    conf_mat_dups = pd.DataFrame(conf_mat_dups, index=[\"Non-Repeater\", \"Repeater\"], columns=[\"Non-Repeater\", \"Repeater\"])\n",
    "    print(\"\\nConfusion Matrix (with duplicates):\")\n",
    "    print(conf_mat_dups)\n",
    "\n",
    "    print(\"accuracy_score\")\n",
    "    accuracy = (all_true_positives.size + all_true_negatives.size) / (all_false_positives.size + all_false_negatives.size + all_true_positives.size + all_true_negatives.size)\n",
    "    print(accuracy)\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=350)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".frb-analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
