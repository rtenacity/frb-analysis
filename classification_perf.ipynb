{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "f0179d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset, ConcatDataset\n",
    "import torch.nn as nn\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, adjusted_rand_score, confusion_matrix, accuracy_score, classification_report, recall_score, f1_score, fbeta_score\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from collections import Counter\n",
    "import umap.umap_ as umap\n",
    "import matplotlib\n",
    "from sklearn.manifold import Isomap\n",
    "from os.path import join\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import pickle\n",
    "import optuna\n",
    "import os\n",
    "from svae import SupervisedVAE, loss_function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "25c5668c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "df = pd.read_csv('chimefrbcat1.csv')\n",
    "\n",
    "df['repeater_name'].value_counts()\n",
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        \n",
    "        \n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "db97410c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['tns_name', 'previous_name', 'repeater_name', 'ra', 'ra_err',\n",
      "       'ra_notes', 'dec', 'dec_err', 'dec_notes', 'gl', 'gb', 'exp_up',\n",
      "       'exp_up_err', 'exp_up_notes', 'exp_low', 'exp_low_err', 'exp_low_notes',\n",
      "       'bonsai_snr', 'bonsai_dm', 'low_ft_68', 'up_ft_68', 'low_ft_95',\n",
      "       'up_ft_95', 'snr_fitb', 'dm_fitb', 'dm_fitb_err', 'dm_exc_ne2001',\n",
      "       'dm_exc_ymw16', 'bc_width', 'scat_time', 'scat_time_err', 'flux',\n",
      "       'flux_err', 'flux_notes', 'fluence', 'fluence_err', 'fluence_notes',\n",
      "       'sub_num', 'mjd_400', 'mjd_400_err', 'mjd_inf', 'mjd_inf_err',\n",
      "       'width_fitb', 'width_fitb_err', 'sp_idx', 'sp_idx_err', 'sp_run',\n",
      "       'sp_run_err', 'high_freq', 'low_freq', 'peak_freq', 'chi_sq', 'dof',\n",
      "       'flag_frac', 'excluded_flag', 'repeater'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "frb_data = pd.read_csv('chimefrbcat1.csv')\n",
    "\n",
    "frb_data.head()\n",
    "\n",
    "def is_repeater(repeater_name):\n",
    "    return 1 if repeater_name != \"-9999\" else 0\n",
    "\n",
    "# Create a new column 'repeater' based on 'repeater_name', if repeater_name is not -9999, set to 1, else 0\n",
    "frb_data['repeater'] = frb_data['repeater_name'].apply(is_repeater)\n",
    "\n",
    "print(frb_data.columns)\n",
    "\n",
    "frb_data['repeater'].value_counts()\n",
    "\n",
    "frb_data.head(15)\n",
    "frb_data['tns_name'].value_counts().head(20)\n",
    "frb_data[\"mjd_400\"] = pd.to_numeric(frb_data[\"mjd_400\"], errors=\"coerce\")\n",
    "\n",
    "# choose the precision that defines sameness\n",
    "PREC = 6  # use 3 if that is what is needed\n",
    "\n",
    "frb_data[\"mjd_400_r\"] = frb_data[\"mjd_400\"].round(PREC)\n",
    "\n",
    "\n",
    "# round MJD to the nearest 3 decimal places\n",
    "mask = frb_data[\"repeater\"] == 0\n",
    "frb_data = pd.concat([\n",
    "    frb_data[mask].drop_duplicates(subset=[\"tns_name\", \"mjd_400_r\"], keep=\"first\"),\n",
    "    frb_data[~mask]\n",
    "])\n",
    "\n",
    "frb_data = frb_data.sort_index()\n",
    "\n",
    "frb_data[frb_data['tns_name']=='FRB20190122C'][['mjd_400_r', 'repeater']].values\n",
    "\n",
    "len(frb_data)\n",
    "labels = frb_data['repeater']\n",
    "\n",
    "base_features = ['bonsai_dm', 'dm_exc_ne2001', 'dm_exc_ymw16', 'bc_width', 'high_freq', 'low_freq', 'peak_freq']\n",
    "error_features = ['dm_fitb', 'fluence', 'flux', 'sp_idx', 'sp_run']\n",
    "\n",
    "all_features = base_features + error_features\n",
    "\n",
    "for feature in all_features:\n",
    "    # convert to integer if the feature is not already an integer\n",
    "    if not pd.api.types.is_integer_dtype(frb_data[feature]):\n",
    "        frb_data[feature] = pd.to_numeric(frb_data[feature]).astype(int)\n",
    "\n",
    "\n",
    "for feature in error_features:\n",
    "    frb_data[f\"{feature}_lower\"] = frb_data[feature] - frb_data[f'{feature}_err']\n",
    "    frb_data[f\"{feature}_upper\"] = frb_data[feature] + frb_data[f'{feature}_err']\n",
    "    \n",
    "\n",
    "new_features = [f\"{feature}_lower\" for feature in error_features] + [f\"{feature}_upper\" for feature in error_features] + base_features\n",
    "\n",
    "\n",
    "\n",
    "frb_data[new_features + ['repeater']].head(15)\n",
    "frb_data_clean = frb_data[new_features].dropna()\n",
    "scaler = StandardScaler()\n",
    "frb_data_scaled = scaler.fit_transform(frb_data_clean)\n",
    "indices = frb_data_clean.index\n",
    "train_data, val_data, train_labels, val_labels, train_indices, val_indices = train_test_split(\n",
    "    frb_data_scaled, labels, indices, test_size=0.2, random_state=42, stratify=labels\n",
    ")\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "train_tensor = torch.tensor(train_data, dtype=torch.float32)\n",
    "val_tensor = torch.tensor(val_data, dtype=torch.float32)\n",
    "train_labels_tensor = torch.tensor(train_labels.values, dtype=torch.long)\n",
    "val_labels_tensor = torch.tensor(val_labels.values, dtype=torch.long)\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "batch_size = 64\n",
    "train_dataset = TensorDataset(train_tensor, train_labels_tensor)\n",
    "val_dataset = TensorDataset(val_tensor, val_labels_tensor)\n",
    "\n",
    "full_dataset = ConcatDataset([train_dataset, val_dataset])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "input_dim = val_tensor.shape[1]\n",
    "hidden_dim = 256\n",
    "latent_dim = 10\n",
    "stop_patience = 8\n",
    "num_epochs = 150\n",
    "\n",
    "def evaluate_classifier(model, dataloader, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for data, labels in dataloader:\n",
    "            data = data.to(device)\n",
    "            labels = labels.to(device)\n",
    "            class_logits = model(data)[-1]\n",
    "            preds = (torch.sigmoid(class_logits) > 0.5).float().cpu().numpy().squeeze()\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    all_preds = np.array(all_preds)\n",
    "    all_labels = np.array(all_labels)\n",
    "    \n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    class_report = classification_report(all_labels, all_preds, target_names=[\"Non-Repeater\", \"Repeater\"])\n",
    "    conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "    recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "    \n",
    "    false_positives = np.sum((all_labels == 0) & (all_preds == 1))\n",
    "\n",
    "    return accuracy, class_report, conf_matrix, recall, false_positives  # Return F1 score as well\n",
    "\n",
    "def get_activation_function(name):\n",
    "    if name == 'ReLU':\n",
    "        return nn.ReLU()\n",
    "    elif name == 'LeakyReLU':\n",
    "        return nn.LeakyReLU(0.1)\n",
    "    elif name == 'ELU':\n",
    "        return nn.ELU()\n",
    "    elif name == 'SELU':\n",
    "        return nn.SELU()\n",
    "    elif name == 'GELU':\n",
    "        return nn.GELU()\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown activation function: {name}\")\n",
    "\n",
    "def evaluate_classifier_full(model, dataloader, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for data, labels in dataloader:\n",
    "            data = data.to(device)\n",
    "            class_logits = model(data)[-1]\n",
    "            preds = (torch.sigmoid(class_logits) > 0.5).float().cpu().numpy().squeeze()\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    all_preds = np.array(all_preds)\n",
    "    all_labels = np.array(all_labels)\n",
    "    \n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds)\n",
    "    class_report = classification_report(all_labels, all_preds, target_names=[\"Non-Repeater\", \"Repeater\"])\n",
    "    conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "    \n",
    "    return accuracy, class_report, conf_matrix, all_preds, all_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "bdaf58cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data = pd.read_csv('chimefrbcat1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "dd14b356",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "garcia_list = '''\n",
    "FRB20180907E\n",
    "FRB20180920B\n",
    "FRB20180928A\n",
    "FRB20181017B\n",
    "FRB20181022E\n",
    "FRB20181125A\n",
    "FRB20181125A\n",
    "FRB20181125A\n",
    "FRB20181214A\n",
    "FRB20181220A\n",
    "FRB20181226E\n",
    "FRB20181229B\n",
    "FRB20190112A\n",
    "FRB20190128C\n",
    "FRB20190206B\n",
    "FRB20190206A\n",
    "FRB20190218B\n",
    "FRB20190223A\n",
    "FRB20190308C\n",
    "FRB20190308C\n",
    "FRB20190323D\n",
    "FRB20190329A\n",
    "FRB20190410A\n",
    "FRB20190412B\n",
    "FRB20190423B\n",
    "FRB20190423B\n",
    "FRB20190429B\n",
    "FRB20190430A\n",
    "FRB20190527A\n",
    "FRB20190527A\n",
    "FRB20190601C\n",
    "FRB20190601C\n",
    "FRB20190617B\n",
    "FRB20180910A\n",
    "FRB20190210C\n",
    "FRB20200726D\n",
    "'''.split()\n",
    "\n",
    "luo_list = '''\n",
    "FRB20181229B\n",
    "FRB20190423B\n",
    "FRB20190410A\n",
    "FRB20181017B\n",
    "FRB20181128C\n",
    "FRB20190422A\n",
    "FRB20190409B\n",
    "FRB20190329A\n",
    "FRB20190423B\n",
    "FRB20190206A\n",
    "FRB20190128C\n",
    "FRB20190106A\n",
    "FRB20190129A\n",
    "FRB20181030E\n",
    "FRB20190527A\n",
    "FRB20190218B\n",
    "FRB20190609A\n",
    "FRB20190412B\n",
    "FRB20190125B\n",
    "FRB20181231B\n",
    "FRB20181221A\n",
    "FRB20190112A\n",
    "FRB20190125A\n",
    "FRB20181218C\n",
    "FRB20190429B\n",
    "FRB20190109B\n",
    "FRB20190206B\n",
    "'''.split()\n",
    "\n",
    "zhu_ge_list = '''\n",
    "FRB20180911A\n",
    "FRB20180915B\n",
    "FRB20180920B\n",
    "FRB20180923A\n",
    "FRB20180923C\n",
    "FRB20180928A\n",
    "FRB20181013E\n",
    "FRB20181017B\n",
    "FRB20181030E\n",
    "FRB20181125A\n",
    "FRB20181125A\n",
    "FRB20181125A\n",
    "FRB20181130A\n",
    "FRB20181214A\n",
    "FRB20181220A\n",
    "FRB20181221A\n",
    "FRB20181226E\n",
    "FRB20181229B\n",
    "FRB20181231B\n",
    "FRB20190106B\n",
    "FRB20190109B\n",
    "FRB20190110C\n",
    "FRB20190111A\n",
    "FRB20190112A\n",
    "FRB20190129A\n",
    "FRB20190204A\n",
    "FRB20190206A\n",
    "FRB20190218B\n",
    "FRB20190220A\n",
    "FRB20190221A\n",
    "FRB20190222B\n",
    "FRB20190223A\n",
    "FRB20190228A\n",
    "FRB20190308C\n",
    "FRB20190308C\n",
    "FRB20190308B\n",
    "FRB20190308B\n",
    "FRB20190323D\n",
    "FRB20190329A\n",
    "FRB20190403E\n",
    "FRB20190409B\n",
    "FRB20190410A\n",
    "FRB20190412B\n",
    "FRB20190418A\n",
    "FRB20190419A\n",
    "FRB20190422A\n",
    "FRB20190422A\n",
    "FRB20190423A\n",
    "FRB20190423B\n",
    "FRB20190423B\n",
    "FRB20190429B\n",
    "FRB20190430A\n",
    "FRB20190517C\n",
    "FRB20190527A\n",
    "FRB20190527A\n",
    "FRB20190531C\n",
    "FRB20190601B\n",
    "FRB20190601C\n",
    "FRB20190601C\n",
    "FRB20190609A\n",
    "FRB20190617A\n",
    "FRB20190617B\n",
    "FRB20190618A\n",
    "FRB20190625A\n",
    "'''.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "46287486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/3 - Validation Accuracy: 0.9789\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Non-Repeater       0.99      0.99      0.99       159\n",
      "    Repeater       0.94      0.94      0.94        31\n",
      "\n",
      "    accuracy                           0.98       190\n",
      "   macro avg       0.96      0.96      0.96       190\n",
      "weighted avg       0.98      0.98      0.98       190\n",
      "\n",
      "Confusion Matrix:\n",
      "[[157   2]\n",
      " [  2  29]]\n",
      "Fold 2/3 - Validation Accuracy: 0.9789\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Non-Repeater       0.98      0.99      0.99       159\n",
      "    Repeater       0.97      0.90      0.93        31\n",
      "\n",
      "    accuracy                           0.98       190\n",
      "   macro avg       0.97      0.95      0.96       190\n",
      "weighted avg       0.98      0.98      0.98       190\n",
      "\n",
      "Confusion Matrix:\n",
      "[[158   1]\n",
      " [  3  28]]\n",
      "Fold 3/3 - Validation Accuracy: 0.9842\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Non-Repeater       0.99      0.99      0.99       158\n",
      "    Repeater       0.97      0.94      0.95        32\n",
      "\n",
      "    accuracy                           0.98       190\n",
      "   macro avg       0.98      0.97      0.97       190\n",
      "weighted avg       0.98      0.98      0.98       190\n",
      "\n",
      "Confusion Matrix:\n",
      "[[157   1]\n",
      " [  2  30]]\n",
      "0.980701754385965\n"
     ]
    }
   ],
   "source": [
    "best_params = {'hidden_dim': 1530, 'latent_dim': 16, 'beta': 1.2211908840673436, 'gamma': 0.5885532829581379, 'dropout_rate': 0.10966445430577035, 'lr': 0.00013082216688850454, 'scheduler_patience': 7, 'class_weight': 0.8946298975578247, 'activation': 'ReLU', 'classification_multiplier': 12452.143276136809}\n",
    "\n",
    "lr = best_params[\"lr\"]\n",
    "scheduler_patience = best_params[\"scheduler_patience\"]\n",
    "num_epochs = 150\n",
    "\n",
    "all_false_positives = []\n",
    "all_false_negatives = []\n",
    "all_true_positives = []\n",
    "all_true_negatives = []\n",
    "\n",
    "val_preds_full = []\n",
    "val_labels_full = []\n",
    "\n",
    "num_epochs = 150\n",
    "\n",
    "n_folds = 3\n",
    "skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "accuracy = 0\n",
    "\n",
    "for fold, (train_index, val_index) in enumerate(skf.split(frb_data_scaled, labels)):\n",
    "# print(f\"\\n=== Fold {fold + 1}/{n_folds} ===\")\n",
    "\n",
    "    train_data, val_data = frb_data_scaled[train_index], frb_data_scaled[val_index]\n",
    "    train_labels, val_labels = labels.iloc[train_index], labels.iloc[val_index]\n",
    "    \n",
    "    train_tensor = torch.tensor(train_data, dtype=torch.float32)\n",
    "    val_tensor = torch.tensor(val_data, dtype=torch.float32)\n",
    "    train_labels_tensor = torch.tensor(train_labels.values, dtype=torch.long)\n",
    "    val_labels_tensor = torch.tensor(val_labels.values, dtype=torch.long)\n",
    "    \n",
    "    train_dataset = TensorDataset(train_tensor, train_labels_tensor)\n",
    "    val_dataset = TensorDataset(val_tensor, val_labels_tensor)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    best_model = SupervisedVAE(\n",
    "        input_dim,\n",
    "        best_params[\"hidden_dim\"],\n",
    "        best_params[\"latent_dim\"],\n",
    "        best_params[\"dropout_rate\"],\n",
    "        get_activation_function(best_params[\"activation\"])\n",
    "    ).to(device)\n",
    "\n",
    "    best_model.load_state_dict(torch.load(f\"saves/trial_224/model_fold_{fold+1}.pth\", map_location=device))\n",
    "        \n",
    "\n",
    "    val_accuracy, val_class_report, val_conf_matrix, val_preds, val_labels = evaluate_classifier_full(best_model, val_loader, device)\n",
    "    \n",
    "    false_positives = original_data.loc[val_index[(val_labels == 0) & (val_preds == 1)], \"tns_name\"]\n",
    "    false_negatives = original_data.loc[val_index[(val_labels == 1) & (val_preds == 0)], \"tns_name\"]\n",
    "    true_positives = original_data.loc[val_index[(val_labels == 1) & (val_preds == 1)], \"tns_name\"]\n",
    "    true_negatives = original_data.loc[val_index[(val_labels == 0) & (val_preds == 0)], \"tns_name\"]\n",
    "    \n",
    "    val_preds_full.extend(val_preds)\n",
    "    val_labels_full.extend(val_labels)\n",
    "\n",
    "    print(f\"Fold {fold + 1}/{n_folds} - Validation Accuracy: {val_accuracy:.4f}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(val_class_report)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(val_conf_matrix)\n",
    "    \n",
    "    all_false_negatives.extend(false_negatives)\n",
    "    all_true_positives.extend(true_positives)\n",
    "    all_true_negatives.extend(true_negatives)\n",
    "    all_false_positives.extend(false_positives)\n",
    "    accuracy += val_accuracy\n",
    "    \n",
    "\n",
    "\n",
    "accuracy /= n_folds\n",
    "\n",
    "\n",
    "all_false_positives = pd.Series(all_false_positives)\n",
    "all_false_negatives = pd.Series(all_false_negatives)\n",
    "all_true_positives = pd.Series(all_true_positives)\n",
    "all_true_negatives = pd.Series(all_true_negatives)\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "e7b467db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=== Summary ===\n",
      "Total False Positives: 4\n",
      "Total False Negatives: 7\n",
      "Total True Positives: 87\n",
      "Total True Negatives: 472\n",
      "\n",
      "Confusion Matrix (with duplicates):\n",
      "              Non-Repeater  Repeater\n",
      "Non-Repeater         472.0       4.0\n",
      "Repeater               7.0      87.0\n",
      "accuracy_score\n",
      "0.980701754385965\n"
     ]
    }
   ],
   "source": [
    "print(\"\")\n",
    "\n",
    "print(\"\\n=== Summary ===\")\n",
    "print(f\"Total False Positives: {all_false_positives.size}\")\n",
    "print(f\"Total False Negatives: {all_false_negatives.size}\")\n",
    "print(f\"Total True Positives: {all_true_positives.size}\")\n",
    "print(f\"Total True Negatives: {all_true_negatives.size}\")\n",
    "\n",
    "conf_mat_dups = np.zeros((2, 2))\n",
    "conf_mat_dups[0, 0] = all_true_negatives.size\n",
    "conf_mat_dups[0, 1] = all_false_positives.size\n",
    "conf_mat_dups[1, 0] = all_false_negatives.size\n",
    "conf_mat_dups[1, 1] = all_true_positives.size\n",
    "\n",
    "\n",
    "conf_mat_dups = pd.DataFrame(conf_mat_dups, index=[\"Non-Repeater\", \"Repeater\"], columns=[\"Non-Repeater\", \"Repeater\"])\n",
    "print(\"\\nConfusion Matrix (with duplicates):\")\n",
    "print(conf_mat_dups)\n",
    "\n",
    "print(\"accuracy_score\")\n",
    "accuracy = (all_true_positives.size + all_true_negatives.size) / (all_false_positives.size + all_false_negatives.size + all_true_positives.size + all_true_negatives.size)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "39c7e838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[472   4]\n",
      " [  7  87]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Non-Repeater     0.9854    0.9916    0.9885       476\n",
      "    Repeater     0.9560    0.9255    0.9405        94\n",
      "\n",
      "    accuracy                         0.9807       570\n",
      "   macro avg     0.9707    0.9586    0.9645       570\n",
      "weighted avg     0.9805    0.9807    0.9806       570\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cm = conf_mat_dups.to_numpy().astype(int)\n",
    "\n",
    "print(cm)\n",
    "y_true = np.concatenate([np.zeros(cm[0].sum()), np.ones(cm[1].sum())])\n",
    "y_pred = np.concatenate([\n",
    "    np.concatenate([np.zeros(cm[0, 0]), np.ones(cm[0, 1])]),\n",
    "    np.concatenate([np.zeros(cm[1, 0]), np.ones(cm[1, 1])])\n",
    "])\n",
    "\n",
    "print(classification_report(y_true, y_pred, target_names=['Non-Repeater', 'Repeater'], digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "ae7f1ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FRB20181218C\n",
      "FRB20190221A\n"
     ]
    }
   ],
   "source": [
    "for fp in all_false_positives:\n",
    "    if fp in luo_list or fp in zhu_ge_list or fp in garcia_list:\n",
    "        print(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "c1b5d3c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FRB20181218C', 'FRB20190122C', 'FRB20190221A', 'FRB20190320A']"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_false_positives.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "9e0d9b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 9,822,649\n",
      "Model size: 37.47 MB\n"
     ]
    }
   ],
   "source": [
    "def get_model_size_and_params(model):\n",
    "    # Total number of parameters\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    \n",
    "\n",
    "    # Each parameter is a float32 (4 bytes)\n",
    "    total_size_bytes = total_params * 4\n",
    "    total_size_mb = total_size_bytes / (1024 ** 2)  # Convert to MB\n",
    "    \n",
    "    print(f\"Total parameters: {total_params:,}\")\n",
    "    print(f\"Model size: {total_size_mb:.2f} MB\")\n",
    "\n",
    "# Example usage:\n",
    "best_model = SupervisedVAE(\n",
    "    input_dim,\n",
    "    best_params[\"hidden_dim\"],\n",
    "    best_params[\"latent_dim\"],\n",
    "    best_params[\"dropout_rate\"],\n",
    "    get_activation_function(best_params[\"activation\"])\n",
    ").to(device)\n",
    "\n",
    "get_model_size_and_params(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "ccb78c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden_dim: 1530\n",
      "latent_dim: 16\n",
      "beta: 1.2212\n",
      "gamma: 0.5886\n",
      "dropout_rate: 0.1097\n",
      "lr: 0.0001\n",
      "scheduler_patience: 7\n",
      "class_weight: 0.8946\n",
      "activation: ReLU\n",
      "classification_multiplier: 12452.1433\n"
     ]
    }
   ],
   "source": [
    "for param in best_params:\n",
    "    if type(best_params[param]) == float:\n",
    "        print(f\"{param}: {best_params[param]:.4f}\")\n",
    "    else:\n",
    "        print(f\"{param}: {best_params[param]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "f124c401",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9807405337693228"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fbeta_score(val_preds_full, val_labels_full, beta=2, average='weighted')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
